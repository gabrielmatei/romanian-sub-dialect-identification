# -*- coding: utf-8 -*-
"""Copy of Romanian sub-dialect identification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14mlxTKppTM9Eb8cyPAWCRzFgK75PtGuf

# Romanian sub-dialect identification
Discriminate between the Moldavian and the Romanian dialects across different text genres (news versus tweets)

## Import libraries
"""

import re
import nltk
import numpy as np
import pandas as pd

"""## Read data"""

def read_file(fileName, convertToList=True):
    BASE_PATH = 'drive/My Drive/ML/3'
    data = pd.read_table(BASE_PATH + '/' + fileName, header = None, encoding = 'utf-8')
    if convertToList:
        data = data[1].tolist()
    return data

x_train = read_file('train_samples.txt')
y_train = read_file('train_labels.txt')

x_test = read_file('validation_samples.txt')
y_test = read_file('validation_labels.txt')

print(len(x_train), len(y_train))
x_train[0], y_train[0]

print(len(y_test), len(y_test))
x_test[0], y_test[0]

x_train = x_train + x_test
y_train = y_train + y_test

print(len(x_train), len(y_train))

"""## Extract features"""

from nltk import ngrams
from nltk import WhitespaceTokenizer

def word_ngrams(tokens, n):
    ngrams_list = []
    ngrams_list.append(list(ngrams(tokens, n)))
    result = []
    for ngram in ngrams_list:
        for gram in ngram:
            result.append(' '.join(gram))
    return result

def char_ngrams(word, n):
    ngrams_list = []
    ngrams_list.append(list(ngrams(word, n, pad_left=True, pad_right=True, left_pad_symbol=' ', right_pad_symbol=' ')))
    if (n > 2):
        redundant_combinations = n - 2
        ngrams_list = [ngram_list[redundant_combinations : -redundant_combinations] for ngram_list in ngrams_list]
    result = []
    for ngram in ngrams_list:
        for gram in ngram:
            result.append(''.join(gram))
    return result

def ngram_features(sent):
    features = {}
    
    sentence_tokens = WhitespaceTokenizer().tokenize(sent)

    for ngram in word_ngrams(sentence_tokens, 1):
        features[f'w1[{ngram}]'] = features.get(f'w1[{ngram}]', 0) + 1
    for ngram in word_ngrams(sentence_tokens, 2):
        features[f'w2[{ngram}]'] = features.get(f'w2[{ngram}]', 0) + 1
    for ngram in word_ngrams(sentence_tokens, 3):
        features[f'w3[{ngram}]'] = features.get(f'w3[{ngram}]', 0) + 1
    
    for word in sentence_tokens:
        for ngram in char_ngrams(word, 1):
            features[f'c1[{ngram}]'] = features.get(f'c1[{ngram}]', 0) + 1
        for ngram in char_ngrams(word, 2):
            features[f'c2[{ngram}]'] = features.get(f'c2[{ngram}]', 0) + 1
        for ngram in char_ngrams(word, 3):
            features[f'c3[{ngram}]'] = features.get(f'c3[{ngram}]', 0) + 1
    
    return features

char_ngrams('dialect', 3)

sentence_tokens = WhitespaceTokenizer().tokenize('Discriminate between the Moldavian and the Romanian dialects across different text genres')
word_ngrams(sentence_tokens, 2)

ngram_features('Ana are mere')

"""## Prepare for training"""

from sklearn.feature_extraction.text import CountVectorizer

count_vect = CountVectorizer(analyzer=ngram_features)

x_train = count_vect.fit_transform(x_train)
x_test = count_vect.transform(x_test)
x_train, x_test

count_vect.vocabulary_

len(count_vect.vocabulary_)

"""## Test multiple classifiers"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report

def show_model_info(name, model, x_test, y_test, y_pred):
    print(name)
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy: {}".format(accuracy))
    plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues, normalize=None, values_format='.0f')
    plt.show()
    print(classification_report(y_test, y_pred))

names = ["K Nearest Neighbors", "Decision Tree", "Random Forest", "Logistic Regression", "SGD Classifier", "Naive Bayes", "SVM Linear"]

classifiers = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    LogisticRegression(max_iter = 100),
    SGDClassifier(max_iter = 100),
    MultinomialNB(),
    SVC(kernel = 'linear')
]

models = list(zip(names, classifiers))

x_train

from nltk.classify.scikitlearn import SklearnClassifier

for name, model in models:
    model.fit(x_train, y_train)  
    y_pred = model.predict(x_test)
    show_model_info(name, model, x_test, y_test, y_pred)

"""## Compare all classifiers"""

from sklearn.ensemble import VotingClassifier

all_model = VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1)
all_model.fit(x_train, y_train) 
y_pred = all_model.predict(x_test)
show_model_info('Voting Classifier', all_model, x_test, y_test, y_pred)

"""## Output"""

test_data = read_file('test_samples.txt', convertToList=False)

test_vec = count_vect.transform(test_data[1])

pred = all_model.predict(test_vec)
pred

submission = pd.DataFrame({'id': test_data[0], 'label': pred})
submission

submission.to_csv('sub16.txt', index=False)